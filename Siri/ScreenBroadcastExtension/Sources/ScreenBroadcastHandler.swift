import ReplayKit
import Foundation
import CoreMedia
import AVFoundation
import AudioToolbox
import os.log

@objc(ScreenBroadcastHandler)
public class ScreenBroadcastHandler: RPBroadcastSampleHandler {
    
    private let logger = Logger(subsystem: "dev.tuist.Siri", category: "ScreenBroadcast")
    private let appGroupID = "group.dev.tuist.Siri"
    
    // çŠ¶æ€ç®¡ç†
    private var isRecording = false
    private var audioFrameCount: Int64 = 0
    
    // éŸ³é¢‘å½•åˆ¶
    private var audioWriter: AVAssetWriter?
    private var audioWriterInput: AVAssetWriterInput?
    private var currentAudioFileURL: URL?
    private var startTime: CMTime?
    
    // MARK: - Broadcast Lifecycle
    
    public override init() {
        super.init()
        logger.info("ğŸ¬ ScreenBroadcastHandler åˆå§‹åŒ–")
    }
    
    public override func broadcastStarted(withSetupInfo setupInfo: [String : NSObject]?) {
        logger.info("ğŸš€ å±å¹•ç›´æ’­å¼€å§‹")
        logger.info("ğŸ“‹ å¯åŠ¨å‚æ•°: \(setupInfo ?? [:])")
        
        // è®¾ç½®å½•åˆ¶çŠ¶æ€
        isRecording = true
        audioFrameCount = 0
        startTime = nil
        
        // å¼€å§‹éŸ³é¢‘å½•åˆ¶
        startAudioRecording()
        
        // é€šçŸ¥ä¸»ç¨‹åºç›´æ’­å·²å¼€å§‹
        updateStatus(status: "started", message: "å±å¹•ç›´æ’­å·²å¼€å§‹")
        
        logger.info("âœ… å±å¹•ç›´æ’­å¯åŠ¨å®Œæˆ")
    }
    
    public override func broadcastFinished() {
        logger.info("ğŸ›‘ å±å¹•ç›´æ’­ç»“æŸ")
        
        isRecording = false
        
        // åœæ­¢éŸ³é¢‘å½•åˆ¶
        stopAudioRecording()
        
        // é€šçŸ¥ä¸»ç¨‹åºç›´æ’­å·²ç»“æŸ
        updateStatus(status: "finished", message: "å±å¹•ç›´æ’­å·²ç»“æŸ")
        
        logger.info("âœ… å±å¹•ç›´æ’­ç»“æŸå®Œæˆ")
    }
    
    public override func finishBroadcastWithError(_ error: Error) {
        logger.error("âŒ å±å¹•ç›´æ’­å‘ç”Ÿé”™è¯¯: \(error.localizedDescription)")
        
        isRecording = false
        
        // åœæ­¢éŸ³é¢‘å½•åˆ¶
        stopAudioRecording()
        
        // é€šçŸ¥ä¸»ç¨‹åºç›´æ’­å‘ç”Ÿé”™è¯¯
        updateStatus(status: "error", message: "ç›´æ’­é”™è¯¯: \(error.localizedDescription)")
        
        logger.error("âŒ å±å¹•ç›´æ’­é”™è¯¯å¤„ç†å®Œæˆ")
        super.finishBroadcastWithError(error)
    }
    
    // MARK: - Sample Buffer Processing
    
    public override func processSampleBuffer(_ sampleBuffer: CMSampleBuffer, with sampleBufferType: RPSampleBufferType) {
        guard isRecording else {
            return
        }
        
        // æ£€æŸ¥æ˜¯å¦æ”¶åˆ°åœæ­¢æŒ‡ä»¤
        checkForStopCommand()
        
        switch sampleBufferType {
        case .audioApp:
            processAppAudio(sampleBuffer)
        case .audioMic:
            processMicAudio(sampleBuffer)
        case .video:
            processVideo(sampleBuffer)
        @unknown default:
            logger.error("âŒ æœªçŸ¥çš„æ ·æœ¬ç¼“å†²åŒºç±»å‹")
        }
    }
    
    // MARK: - Audio Processing
    
    private func processAppAudio(_ sampleBuffer: CMSampleBuffer) {
        audioFrameCount += 1
        
        // ä¿å­˜éŸ³é¢‘æ•°æ®åˆ°æ–‡ä»¶
        saveAudioToFile(sampleBuffer)
        
        // å‘é€å®æ—¶éŸ³é¢‘æ•°æ®ç»™ä¸»ç¨‹åºè¿›è¡Œè¯†åˆ«
        sendAudioDataForRecognition(sampleBuffer)
        
        // è®¡ç®—éŸ³é¢‘ç”µå¹³
        let audioLevel = calculateAudioLevel(sampleBuffer: sampleBuffer)
        
        // æ¯ 30 å¸§å‘é€ä¸€æ¬¡éŸ³é¢‘æ•°æ®åˆ°ä¸»ç¨‹åº
        if audioFrameCount % 30 == 0 {
            sendAudioDataToMainApp(audioLevel: audioLevel, frameCount: audioFrameCount)
        }
    }
    
    private func processMicAudio(_ sampleBuffer: CMSampleBuffer) {
        // å¤„ç†éº¦å…‹é£éŸ³é¢‘ï¼ˆå¦‚æœéœ€è¦ï¼‰
        logger.debug("ğŸ¤ æ”¶åˆ°éº¦å…‹é£éŸ³é¢‘æ•°æ®")
    }
    
    private func processVideo(_ sampleBuffer: CMSampleBuffer) {
        // å¤„ç†è§†é¢‘æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
        logger.debug("ğŸ“¹ æ”¶åˆ°è§†é¢‘æ•°æ®")
    }
    
    // MARK: - Audio Level Calculation
    
    private func calculateAudioLevel(sampleBuffer: CMSampleBuffer) -> Double {
        guard let blockBuffer = CMSampleBufferGetDataBuffer(sampleBuffer) else {
            return 0.0
        }
        
        var dataPointer: UnsafeMutablePointer<Int8>?
        var dataLength: Int = 0
        
        let status = CMBlockBufferGetDataPointer(blockBuffer, atOffset: 0, lengthAtOffsetOut: nil, totalLengthOut: &dataLength, dataPointerOut: &dataPointer)
        
        guard status == noErr, let pointer = dataPointer, dataLength > 0 else {
            return 0.0
        }
        
        // å°†æ•°æ®è½¬æ¢ä¸º Float å¹¶è®¡ç®— RMS
        let samples = pointer.withMemoryRebound(to: Float.self, capacity: dataLength / MemoryLayout<Float>.size) { floatPointer in
            Array(UnsafeBufferPointer(start: floatPointer, count: dataLength / MemoryLayout<Float>.size))
        }
        
        if samples.isEmpty {
            return 0.0
        }
        
        // è®¡ç®— RMS (Root Mean Square)
        let sum = samples.reduce(0.0) { $0 + ($1 * $1) }
        let rms = sqrt(Double(sum) / Double(samples.count))
        
        // è½¬æ¢ä¸ºåˆ†è´å¹¶è§„èŒƒåŒ–åˆ° 0-1 èŒƒå›´
        let decibels = 20 * log10(max(rms, 1e-7))
        let normalizedLevel = max(0.0, min(1.0, (decibels + 60) / 60))
        
        return normalizedLevel
    }
    
    // MARK: - Communication with Main App
    
    private func sendAudioDataToMainApp(audioLevel: Double, frameCount: Int64) {
        let audioData: [String: Any] = [
            "audioLevel": audioLevel,
            "frameCount": frameCount,
            "timestamp": Date().timeIntervalSince1970,
            "isRecording": isRecording
        ]
        
        writeToAppGroup(fileName: "audio_data.json", data: audioData)
        
        logger.info("ğŸµ å‘é€éŸ³é¢‘æ•°æ®: ç”µå¹³=\(String(format: "%.3f", audioLevel)), å¸§æ•°=\(frameCount)")
    }
    
    private func updateStatus(status: String, message: String) {
        let statusData: [String: Any] = [
            "status": status,
            "message": message,
            "timestamp": Date().timeIntervalSince1970,
            "isRecording": isRecording
        ]
        
        writeToAppGroup(fileName: "broadcast_status.json", data: statusData)
        logger.info("ğŸ“¡ çŠ¶æ€æ›´æ–°: \(status) - \(message)")
    }
    
    // MARK: - File System Communication
    
    private func writeToAppGroup(fileName: String, data: [String: Any]) {
        guard let containerURL = FileManager.default.containerURL(forSecurityApplicationGroupIdentifier: appGroupID) else {
            logger.error("âŒ æ— æ³•è·å–App Groupå®¹å™¨è·¯å¾„")
            return
        }
        
        let fileURL = containerURL.appendingPathComponent(fileName)
        
        do {
            let jsonData = try JSONSerialization.data(withJSONObject: data, options: [])
            try jsonData.write(to: fileURL)
        } catch {
            logger.error("âŒ å†™å…¥App Groupæ–‡ä»¶å¤±è´¥: \(error.localizedDescription)")
        }
    }
    
    // MARK: - Stop Command Processing
    
    private func checkForStopCommand() {
        guard let containerURL = FileManager.default.containerURL(forSecurityApplicationGroupIdentifier: appGroupID) else {
            return
        }
        
        let stopCommandURL = containerURL.appendingPathComponent("stop_command.json")
        
        if FileManager.default.fileExists(atPath: stopCommandURL.path) {
            logger.info("ğŸ“¥ æ”¶åˆ°ä¸»ç¨‹åºåœæ­¢æŒ‡ä»¤")
            
            // åˆ é™¤æŒ‡ä»¤æ–‡ä»¶
            try? FileManager.default.removeItem(at: stopCommandURL)
            
            // åœæ­¢ç›´æ’­
            finishBroadcastWithError(NSError(domain: "UserRequested", code: 0, userInfo: [NSLocalizedDescriptionKey: "ç”¨æˆ·é€šè¿‡ä¸»ç¨‹åºåœæ­¢ç›´æ’­"]))
        }
    }
    
    // MARK: - Audio Recording Methods
    
    private func startAudioRecording() {
        guard let containerURL = FileManager.default.containerURL(forSecurityApplicationGroupIdentifier: appGroupID) else {
            logger.error("âŒ æ— æ³•è·å–App Groupå®¹å™¨è·¯å¾„")
            return
        }
        
        // åˆ›å»ºéŸ³é¢‘ç›®å½•
        let audioDirectory = containerURL.appendingPathComponent("AudioRecordings")
        if !FileManager.default.fileExists(atPath: audioDirectory.path) {
            do {
                try FileManager.default.createDirectory(at: audioDirectory, withIntermediateDirectories: true, attributes: nil)
            } catch {
                logger.error("âŒ åˆ›å»ºéŸ³é¢‘ç›®å½•å¤±è´¥: \(error.localizedDescription)")
                return
            }
        }
        
        // åˆ›å»ºéŸ³é¢‘æ–‡ä»¶
        let timestamp = DateFormatter.localizedString(from: Date(), dateStyle: .none, timeStyle: .medium).replacingOccurrences(of: ":", with: "-")
        let fileName = "SystemAudio_\(timestamp).m4a"
        currentAudioFileURL = audioDirectory.appendingPathComponent(fileName)
        
        guard let audioFileURL = currentAudioFileURL else { return }
        
        // è®¾ç½®éŸ³é¢‘å†™å…¥å™¨
        do {
            audioWriter = try AVAssetWriter(outputURL: audioFileURL, fileType: .m4a)
            
            // é…ç½®éŸ³é¢‘è®¾ç½®
            let audioSettings: [String: Any] = [
                AVFormatIDKey: kAudioFormatMPEG4AAC,
                AVSampleRateKey: 44100.0,
                AVNumberOfChannelsKey: 2,
                AVEncoderBitRateKey: 128000
            ]
            
            audioWriterInput = AVAssetWriterInput(mediaType: .audio, outputSettings: audioSettings)
            audioWriterInput?.expectsMediaDataInRealTime = true
            
            if let input = audioWriterInput {
                audioWriter?.add(input)
                audioWriter?.startWriting()
            }
            
            logger.info("ğŸ™ï¸ å¼€å§‹å½•åˆ¶éŸ³é¢‘: \(fileName)")
            
            // é€šçŸ¥ä¸»ç¨‹åºæ–°æ–‡ä»¶å·²åˆ›å»º
            notifyAudioFileCreated(fileName: fileName, fileURL: audioFileURL)
            
        } catch {
            logger.error("âŒ åˆ›å»ºéŸ³é¢‘å†™å…¥å™¨å¤±è´¥: \(error.localizedDescription)")
        }
    }
    
    private func stopAudioRecording() {
        guard let writer = audioWriter else { return }
        
        audioWriterInput?.markAsFinished()
        
        // ä¿å­˜URLçš„å‰¯æœ¬ï¼Œé˜²æ­¢åœ¨å¼‚æ­¥å—ä¸­è¢«æ¸…ç©º
        let audioFileURL = currentAudioFileURL
        
        writer.finishWriting { [weak self] in
            if writer.status == .completed {
                self?.logger.info("âœ… éŸ³é¢‘æ–‡ä»¶å½•åˆ¶å®Œæˆ")
                if let url = audioFileURL {
                    self?.notifyAudioFileCompleted(fileURL: url)
                    self?.logger.info("ğŸ“ M4Aæ–‡ä»¶å·²ä¿å­˜: \(url.lastPathComponent)")
                }
            } else if let error = writer.error {
                self?.logger.error("âŒ éŸ³é¢‘æ–‡ä»¶å†™å…¥å¤±è´¥: \(error.localizedDescription)")
            }
            
            // åœ¨å¼‚æ­¥å—å†…æ¸…ç†å¼•ç”¨
            self?.audioWriter = nil
            self?.audioWriterInput = nil
            self?.currentAudioFileURL = nil
        }
    }
    
    private func saveAudioToFile(_ sampleBuffer: CMSampleBuffer) {
        guard let writer = audioWriter,
              let input = audioWriterInput,
              writer.status == .writing,
              input.isReadyForMoreMediaData else {
            return
        }
        
        // è®¾ç½®å¼€å§‹æ—¶é—´
        if startTime == nil {
            startTime = CMSampleBufferGetPresentationTimeStamp(sampleBuffer)
            writer.startSession(atSourceTime: startTime!)
        }
        
        // å†™å…¥éŸ³é¢‘æ•°æ®
        input.append(sampleBuffer)
    }
    
    private func notifyAudioFileCreated(fileName: String, fileURL: URL) {
        let notification: [String: Any] = [
            "event": "audio_file_created",
            "fileName": fileName,
            "filePath": fileURL.path,
            "timestamp": Date().timeIntervalSince1970
        ]
        
        writeToAppGroup(fileName: "audio_notification.json", data: notification)
    }
    
    private func notifyAudioFileCompleted(fileURL: URL) {
        let notification: [String: Any] = [
            "event": "audio_file_completed",
            "fileName": fileURL.lastPathComponent,
            "filePath": fileURL.path,
            "timestamp": Date().timeIntervalSince1970
        ]
        
        writeToAppGroup(fileName: "audio_notification.json", data: notification)
    }
    
    // MARK: - Realtime Audio Recognition
    
    private func sendAudioDataForRecognition(_ sampleBuffer: CMSampleBuffer) {
        guard let containerURL = FileManager.default.containerURL(forSecurityApplicationGroupIdentifier: appGroupID) else {
            logger.error("âŒ [Extension] æ— æ³•è·å–App Groupå®¹å™¨")
            return
        }
        
        // è·å–éŸ³é¢‘æ ¼å¼æè¿°
        guard let formatDescription = CMSampleBufferGetFormatDescription(sampleBuffer) else {
            logger.error("âŒ [Extension] æ— æ³•è·å–éŸ³é¢‘æ ¼å¼æè¿°")
            return
        }
        
        let audioStreamBasicDescription = CMAudioFormatDescriptionGetStreamBasicDescription(formatDescription)
        guard let streamDescription = audioStreamBasicDescription else {
            logger.error("âŒ [Extension] æ— æ³•è·å–éŸ³é¢‘æµæè¿°")
            return
        }
        
        logger.info("ğŸµ [Extension] éŸ³é¢‘æ ¼å¼ - é‡‡æ ·ç‡: \(streamDescription.pointee.mSampleRate), å£°é“: \(streamDescription.pointee.mChannelsPerFrame), æ ¼å¼: \(streamDescription.pointee.mFormatID)")
        
        // æå–éŸ³é¢‘æ•°æ®
        guard let blockBuffer = CMSampleBufferGetDataBuffer(sampleBuffer) else {
            logger.error("âŒ [Extension] æ— æ³•è·å–éŸ³é¢‘ç¼“å†²åŒº")
            return
        }
        
        var dataPointer: UnsafeMutablePointer<Int8>?
        var dataLength: Int = 0
        
        let status = CMBlockBufferGetDataPointer(blockBuffer, atOffset: 0, lengthAtOffsetOut: nil, totalLengthOut: &dataLength, dataPointerOut: &dataPointer)
        
        guard status == noErr, let pointer = dataPointer, dataLength > 0 else {
            logger.error("âŒ [Extension] éŸ³é¢‘æ•°æ®æŒ‡é’ˆè·å–å¤±è´¥")
            return
        }
        
        // åˆ›å»ºéŸ³é¢‘æ ¼å¼ä¿¡æ¯å­—å…¸
        let audioFormatInfo: [String: Any] = [
            "sampleRate": streamDescription.pointee.mSampleRate,
            "channels": streamDescription.pointee.mChannelsPerFrame,
            "formatID": streamDescription.pointee.mFormatID,
            "formatFlags": streamDescription.pointee.mFormatFlags,  // å…³é”®ï¼šæ·»åŠ formatFlags
            "bitsPerChannel": streamDescription.pointee.mBitsPerChannel,
            "bytesPerFrame": streamDescription.pointee.mBytesPerFrame,
            "framesPerPacket": streamDescription.pointee.mFramesPerPacket,
            "bytesPerPacket": streamDescription.pointee.mBytesPerPacket,
            "dataLength": dataLength
        ]
        
        // å°†éŸ³é¢‘æ•°æ®å’Œæ ¼å¼ä¿¡æ¯åˆ†åˆ«å†™å…¥å…±äº«å†…å­˜
        let audioData = Data(bytes: pointer, count: dataLength)
        let bufferURL = containerURL.appendingPathComponent("realtime_audio_buffer.data")
        let formatURL = containerURL.appendingPathComponent("realtime_audio_format.json")
        
        do {
            // å†™å…¥éŸ³é¢‘æ•°æ®
            try audioData.write(to: bufferURL)
            
            // å†™å…¥æ ¼å¼ä¿¡æ¯
            let formatData = try JSONSerialization.data(withJSONObject: audioFormatInfo, options: [])
            try formatData.write(to: formatURL)
            
            // å‘é€Darwiné€šçŸ¥å‘ŠçŸ¥ä¸»ç¨‹åºæœ‰æ–°éŸ³é¢‘æ•°æ®
            let darwinCenter = CFNotificationCenterGetDarwinNotifyCenter()
            let notificationName = CFNotificationName("dev.tuist.Siri.audiodata" as CFString)
            CFNotificationCenterPostNotification(darwinCenter, notificationName, nil, nil, true)
            
            logger.debug("âœ… [Extension] éŸ³é¢‘æ•°æ®å·²å‘é€: \(dataLength) bytes, æ ¼å¼: \(streamDescription.pointee.mFormatID)")
            
        } catch {
            logger.error("âŒ [Extension] å†™å…¥éŸ³é¢‘æ•°æ®å¤±è´¥: \(error.localizedDescription)")
        }
    }
    
    // MARK: - M4A to WAV Conversion
    
    private func convertM4AToWAV(m4aURL: URL) {
        logger.info("ğŸ“Œ convertM4AToWAV å‡½æ•°è¢«è°ƒç”¨")
        logger.info("ğŸ“‚ è¾“å…¥æ–‡ä»¶: \(m4aURL.path)")
        
        // æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if !FileManager.default.fileExists(atPath: m4aURL.path) {
            logger.error("âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: \(m4aURL.path)")
            return
        }
        
        // åˆ›å»ºWAVæ–‡ä»¶è·¯å¾„
        let wavFileName = m4aURL.lastPathComponent.replacingOccurrences(of: ".m4a", with: "_converted.wav")
        let wavURL = m4aURL.deletingLastPathComponent().appendingPathComponent(wavFileName)
        
        logger.info("ğŸ”„ å¼€å§‹è½¬æ¢ M4A åˆ° WAV")
        logger.info("ğŸ“¥ æºæ–‡ä»¶: \(m4aURL.lastPathComponent)")
        logger.info("ğŸ“¤ ç›®æ ‡æ–‡ä»¶: \(wavFileName)")
        logger.info("ğŸ“ ç›®æ ‡è·¯å¾„: \(wavURL.path)")
        
        if convertM4AToWAVUsingExtAudioFile(inputURL: m4aURL, outputURL: wavURL) {
            logger.info("âœ… WAVè½¬æ¢æˆåŠŸ: \(wavFileName)")
            
            // éªŒè¯è¾“å‡ºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if FileManager.default.fileExists(atPath: wavURL.path) {
                logger.info("âœ… WAVæ–‡ä»¶å·²åˆ›å»º: \(wavURL.path)")
                
                // è·å–æ–‡ä»¶å¤§å°
                if let attributes = try? FileManager.default.attributesOfItem(atPath: wavURL.path),
                   let fileSize = attributes[.size] as? Int64 {
                    logger.info("ğŸ“Š WAVæ–‡ä»¶å¤§å°: \(fileSize) bytes")
                }
            } else {
                logger.error("âŒ WAVæ–‡ä»¶åˆ›å»ºå¤±è´¥ï¼Œæ–‡ä»¶ä¸å­˜åœ¨")
            }
            
            // é€šçŸ¥ä¸»ç¨‹åºWAVæ–‡ä»¶å·²åˆ›å»º
            let notification: [String: Any] = [
                "event": "wav_file_converted",
                "fileName": wavFileName,
                "filePath": wavURL.path,
                "originalFile": m4aURL.lastPathComponent,
                "timestamp": Date().timeIntervalSince1970
            ]
            
            writeToAppGroup(fileName: "wav_conversion_notification.json", data: notification)
        } else {
            logger.error("âŒ WAVè½¬æ¢å¤±è´¥")
        }
    }
    
    private func convertM4AToWAVUsingExtAudioFile(inputURL: URL, outputURL: URL) -> Bool {
        var inputFile: ExtAudioFileRef?
        var outputFile: ExtAudioFileRef?
        
        // æ‰“å¼€è¾“å…¥æ–‡ä»¶
        var status = ExtAudioFileOpenURL(inputURL as CFURL, &inputFile)
        guard status == noErr, let inputFile = inputFile else {
            logger.error("âŒ æ— æ³•æ‰“å¼€è¾“å…¥æ–‡ä»¶: \(inputURL.lastPathComponent)")
            return false
        }
        
        // è·å–è¾“å…¥æ–‡ä»¶æ ¼å¼
        var inputFormat = AudioStreamBasicDescription()
        var size = UInt32(MemoryLayout<AudioStreamBasicDescription>.size)
        ExtAudioFileGetProperty(inputFile, kExtAudioFileProperty_FileDataFormat, &size, &inputFormat)
        
        logger.info("ğŸ“Š è¾“å…¥æ ¼å¼: é‡‡æ ·ç‡=\(inputFormat.mSampleRate), å£°é“=\(inputFormat.mChannelsPerFrame)")
        
        // è®¾ç½®è¾“å‡ºæ ¼å¼ (WAV PCM) - æ·»åŠ æ­£ç¡®çš„å­—èŠ‚åºæ ‡å¿—
        var outputFormat = AudioStreamBasicDescription()
        outputFormat.mSampleRate = inputFormat.mSampleRate
        outputFormat.mFormatID = kAudioFormatLinearPCM
        outputFormat.mFormatFlags = kAudioFormatFlagIsSignedInteger | kAudioFormatFlagIsPacked | kAudioFormatFlagsNativeEndian
        outputFormat.mBitsPerChannel = 16
        outputFormat.mChannelsPerFrame = inputFormat.mChannelsPerFrame
        outputFormat.mBytesPerFrame = outputFormat.mChannelsPerFrame * 2
        outputFormat.mFramesPerPacket = 1
        outputFormat.mBytesPerPacket = outputFormat.mBytesPerFrame
        
        logger.info("ğŸ“¤ è¾“å‡ºæ ¼å¼: PCM 16-bit, \(outputFormat.mSampleRate)Hz, \(outputFormat.mChannelsPerFrame)å£°é“")
        
        // åˆ›å»ºè¾“å‡ºæ–‡ä»¶
        status = ExtAudioFileCreateWithURL(
            outputURL as CFURL,
            kAudioFileWAVEType,
            &outputFormat,
            nil,
            AudioFileFlags.eraseFile.rawValue,
            &outputFile
        )
        
        guard status == noErr, let outputFile = outputFile else {
            ExtAudioFileDispose(inputFile)
            logger.error("âŒ æ— æ³•åˆ›å»ºè¾“å‡ºæ–‡ä»¶: \(outputURL.lastPathComponent)")
            return false
        }
        
        // è®¾ç½®å®¢æˆ·ç«¯æ•°æ®æ ¼å¼
        status = ExtAudioFileSetProperty(inputFile, kExtAudioFileProperty_ClientDataFormat, size, &outputFormat)
        guard status == noErr else {
            logger.error("âŒ è®¾ç½®å®¢æˆ·ç«¯æ•°æ®æ ¼å¼å¤±è´¥: \(status)")
            ExtAudioFileDispose(inputFile)
            ExtAudioFileDispose(outputFile)
            return false
        }
        
        // è·å–æ–‡ä»¶é•¿åº¦ä¿¡æ¯
        var fileLengthFrames: Int64 = 0
        var propertySize = UInt32(MemoryLayout<Int64>.size)
        ExtAudioFileGetProperty(inputFile, kExtAudioFileProperty_FileLengthFrames, &propertySize, &fileLengthFrames)
        logger.info("ğŸ“ è¾“å…¥æ–‡ä»¶æ€»å¸§æ•°: \(fileLengthFrames)")
        
        // è¯»å–å¹¶å†™å…¥æ•°æ®
        let bufferSize: UInt32 = 4096
        let buffer = UnsafeMutablePointer<UInt8>.allocate(capacity: Int(bufferSize))
        defer { buffer.deallocate() }
        
        var bufferList = AudioBufferList()
        bufferList.mNumberBuffers = 1
        bufferList.mBuffers.mNumberChannels = outputFormat.mChannelsPerFrame
        bufferList.mBuffers.mDataByteSize = bufferSize
        bufferList.mBuffers.mData = UnsafeMutableRawPointer(buffer)
        
        var totalFrames: UInt32 = 0
        
        while true {
            var frameCount: UInt32 = bufferSize / outputFormat.mBytesPerFrame
            
            // é‡ç½®bufferå¤§å°
            bufferList.mBuffers.mDataByteSize = bufferSize
            
            status = ExtAudioFileRead(inputFile, &frameCount, &bufferList)
            
            if status != noErr {
                logger.error("âŒ è¯»å–å¤±è´¥: çŠ¶æ€ç =\(status)")
                break
            }
            
            if frameCount == 0 { 
                logger.info("âœ… è¯»å–å®Œæˆ")
                break 
            }
            
            totalFrames += frameCount
            
            status = ExtAudioFileWrite(outputFile, frameCount, &bufferList)
            guard status == noErr else {
                logger.error("âŒ å†™å…¥å¤±è´¥: çŠ¶æ€ç =\(status)")
                break
            }
            
            // æ¯å¤„ç†ä¸€å®šæ•°é‡çš„å¸§è¾“å‡ºè¿›åº¦
            if totalFrames % 10000 == 0 {
                logger.info("â³ å·²è½¬æ¢ \(totalFrames) å¸§...")
            }
        }
        
        logger.info("ğŸ“ å…±è½¬æ¢ \(totalFrames) å¸§éŸ³é¢‘æ•°æ®")
        
        // æ¸…ç†
        ExtAudioFileDispose(inputFile)
        ExtAudioFileDispose(outputFile)
        
        return true
    }
}
